import streamlit as st
import pandas as pd
import unicodedata
import re
import time
from bs4 import BeautifulSoup
import requests

# === è¨­å®š ===
HEADERS = {"User-Agent": "Mozilla/5.0"}

# === ã‚¦ãƒå¨˜è¡€çµ± ===
umamusume_bloodlines = {"ã‚¢ãƒ¼ãƒ¢ãƒ³ãƒ‰ã‚¢ã‚¤", "ã‚¢ã‚¤ãƒã‚¹ãƒ•ã‚¦ã‚¸ãƒ³", "ã‚¢ã‚°ãƒã‚¹ã‚¿ã‚­ã‚ªãƒ³", "ã‚¢ã‚°ãƒã‚¹ãƒ‡ã‚¸ã‚¿ãƒ«", "ã‚¢ã‚¹ãƒˆãƒ³ãƒãƒ¼ãƒãƒ£ãƒ³", "ã‚¢ãƒ‰ãƒã‚¤ãƒ¤ãƒ™ã‚¬", "ã‚¤ã‚¯ãƒãƒ‡ã‚£ã‚¯ã‚¿ã‚¹", "ã‚¤ãƒŠãƒªãƒ¯ãƒ³",
    "ã‚¦ã‚¤ãƒ‹ãƒ³ã‚°ãƒã‚±ãƒƒãƒˆ", "ãƒ´ã‚£ãƒ–ãƒ­ã‚¹", "ãƒ´ã‚£ãƒ«ã‚·ãƒ¼ãƒŠ", "ã‚¦ã‚¤ãƒ³ãƒãƒªã‚¢ã‚·ã‚ªãƒ³", "ã‚¦ã‚ªãƒƒã‚«", "ã‚¨ã‚¢ã‚°ãƒ«ãƒ¼ãƒ´", "ã‚¨ã‚¢ã‚·ãƒ£ã‚«ãƒ¼ãƒ«", "ã‚¨ã‚¢ãƒ¡ã‚µã‚¤ã‚¢",
    "ã‚¨ã‚¤ã‚·ãƒ³ãƒ•ãƒ©ãƒƒã‚·ãƒ¥", "ã‚¨ã‚¹ãƒãƒ¯ãƒ¼ãƒ«ã‚·ãƒãƒ¼", "ã‚¨ãƒ«ã‚³ãƒ³ãƒ‰ãƒ«ãƒ‘ã‚µãƒ¼", "ã‚ªã‚°ãƒªã‚­ãƒ£ãƒƒãƒ—", "ã‚ªãƒ«ãƒ•ã‚§ãƒ¼ãƒ´ãƒ«", "ã‚«ãƒ„ãƒ©ã‚®ã‚¨ãƒ¼ã‚¹", "ã‚«ãƒ«ã‚¹ãƒˆãƒ³ãƒ©ã‚¤ãƒˆã‚ª",
    "ã‚«ãƒ¬ãƒ³ãƒãƒ£ãƒ³", "ã‚«ãƒ¬ãƒ³ãƒ–ãƒ¼ã‚±ãƒ‰ãƒ¼ãƒ«", "ã‚«ãƒ¯ã‚«ãƒŸãƒ—ãƒªãƒ³ã‚»ã‚¹", "ã‚­ã‚¿ã‚µãƒ³ãƒ–ãƒ©ãƒƒã‚¯", "ã‚­ãƒ³ã‚°ãƒ˜ã‚¤ãƒ­ãƒ¼", "ã‚°ãƒ©ã‚¹ãƒ¯ãƒ³ãƒ€ãƒ¼", "ã‚°ãƒ©ãƒ³ã‚¢ãƒ¬ã‚°ãƒªã‚¢",
    "ã‚¯ãƒ­ãƒã‚¸ã‚§ãƒã‚·ã‚¹", "ã‚±ã‚¤ã‚¨ã‚¹ãƒŸãƒ©ã‚¯ãƒ«", "ã‚´ãƒ¼ãƒ«ãƒ‰ã‚·ãƒãƒ¼", "ã‚´ãƒ¼ãƒ«ãƒ‰ã‚·ãƒƒãƒ—", "ã‚³ãƒ‘ãƒãƒªãƒƒã‚­ãƒ¼", "ã‚µã‚¤ãƒ¬ãƒ³ã‚¹ã‚¹ã‚ºã‚«", "ã‚µã‚¦ãƒ³ã‚ºã‚ªãƒ–ã‚¢ãƒ¼ã‚¹",
    "ã‚µã‚¯ãƒ©ãƒãƒˆã‚»ã‚ªãƒ¼", "ã‚µã‚¯ãƒ©ãƒãƒ¨ãƒã‚ªãƒ¼", "ã‚µã‚¯ãƒ©ãƒã‚¯ã‚·ãƒ³ã‚ªãƒ¼", "ã‚µã‚¯ãƒ©ãƒ­ãƒ¼ãƒ¬ãƒ«", "ã‚µãƒˆãƒã‚¯ãƒ©ã‚¦ãƒ³", "ã‚µãƒˆãƒãƒ€ã‚¤ãƒ¤ãƒ¢ãƒ³ãƒ‰", "ã‚µãƒ ã‚½ãƒ³ãƒ“ãƒƒã‚°",
    "ã‚·ãƒ¼ã‚­ãƒ³ã‚°ã‚¶ãƒ‘ãƒ¼ãƒ«", "ã‚·ãƒ¼ã‚¶ãƒªã‚ª", "ã‚¸ã‚§ãƒ³ãƒ†ã‚£ãƒ«ãƒ‰ãƒ³ãƒŠ", "ã‚¸ãƒ£ãƒ³ã‚°ãƒ«ãƒã‚±ãƒƒãƒˆ", "ã‚·ãƒ¥ãƒ´ã‚¡ãƒ«ã‚°ãƒ©ãƒ³", "ã‚·ãƒªã‚¦ã‚¹ã‚·ãƒ³ãƒœãƒª", "ã‚·ãƒ³ã‚³ã‚¦ã‚¦ã‚¤ãƒ³ãƒ‡ã‚£",
    "ã‚·ãƒ³ãƒœãƒªã‚¯ãƒªã‚¹ã‚¨ã‚¹", "ã‚·ãƒ³ãƒœãƒªãƒ«ãƒ‰ãƒ«ãƒ•", "ã‚¹ã‚¤ãƒ¼ãƒ—ãƒˆã‚¦ã‚·ãƒ§ã‚¦", "ã‚¹ãƒ¼ãƒ‘ãƒ¼ã‚¯ãƒªãƒ¼ã‚¯", "ã‚¹ãƒ†ã‚¤ã‚´ãƒ¼ãƒ«ãƒ‰", "ã‚¹ãƒ†ã‚£ãƒ«ã‚¤ãƒ³ãƒ©ãƒ–", "ã‚¹ãƒšã‚·ãƒ£ãƒ«ã‚¦ã‚£ãƒ¼ã‚¯",
    "ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚¡ãƒ«ã‚³ãƒ³", "ã‚»ã‚¤ã‚¦ãƒ³ã‚¹ã‚«ã‚¤", "ã‚¼ãƒ³ãƒãƒ­ãƒ–ãƒ­ã‚¤", "ãƒ€ã‚¤ã‚¤ãƒãƒ«ãƒ“ãƒ¼", "ã‚¿ã‚¤ã‚­ã‚·ãƒ£ãƒˆãƒ«", "ãƒ€ã‚¤ã‚¿ã‚¯ãƒ˜ãƒªã‚ªã‚¹", "ãƒ€ã‚¤ãƒ¯ã‚¹ã‚«ãƒ¼ãƒ¬ãƒƒãƒˆ",
    "ã‚¿ãƒƒãƒ—ãƒ€ãƒ³ã‚¹ã‚·ãƒãƒ¼", "ã‚¿ãƒ‹ãƒã‚®ãƒ ãƒ¬ãƒƒãƒˆ", "ã‚¿ãƒãƒ¢ã‚¯ãƒ­ã‚¹", "ãƒ€ãƒ³ãƒ„ãƒ•ãƒ¬ãƒ¼ãƒ ", "ãƒ„ã‚¤ãƒ³ã‚¿ãƒ¼ãƒœ", "ãƒ„ãƒ«ãƒãƒ«ãƒ„ãƒ¨ã‚·", "ãƒ‡ã‚¢ãƒªãƒ³ã‚°ã‚¿ã‚¯ãƒˆ",
    "ãƒ‡ã‚¢ãƒªãƒ³ã‚°ãƒãƒ¼ãƒˆ", "ãƒ†ã‚¤ã‚¨ãƒ ã‚ªãƒšãƒ©ã‚ªãƒ¼", "ãƒ‡ãƒ¥ãƒ©ãƒ³ãƒ€ãƒ«", "ãƒˆã‚¦ã‚«ã‚¤ãƒ†ã‚¤ã‚ªãƒ¼", "ãƒ‰ã‚¥ãƒ©ãƒ¡ãƒ³ãƒ†", "ãƒˆãƒ¼ã‚»ãƒ³ã‚¸ãƒ§ãƒ¼ãƒ€ãƒ³", "ãƒˆãƒ©ãƒ³ã‚»ãƒ³ãƒ‰",
    "ãƒ‰ãƒªãƒ¼ãƒ ã‚¸ãƒ£ãƒ¼ãƒ‹ãƒ¼", "ãƒŠã‚¤ã‚¹ãƒã‚¤ãƒãƒ£", "ãƒŠã‚«ãƒ¤ãƒãƒ•ã‚§ã‚¹ã‚¿", "ãƒŠãƒªã‚¿ã‚¿ã‚¤ã‚·ãƒ³", "ãƒŠãƒªã‚¿ãƒˆãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", "ãƒŠãƒªã‚¿ãƒ–ãƒ©ã‚¤ã‚¢ãƒ³", "ãƒ‹ã‚·ãƒãƒ•ãƒ©ãƒ¯ãƒ¼",
    "ãƒã‚ªãƒ¦ãƒ‹ãƒ´ã‚¡ãƒ¼ã‚¹", "ãƒãƒ¼ã‚¹ãƒ•ãƒ©ã‚¤ãƒˆ", "ãƒãƒ¼ãƒªãƒ¼ã‚ºãƒ³", "ãƒãƒ–ãƒ«ã‚¬ãƒ ãƒ•ã‚§ãƒ­ãƒ¼", "ãƒãƒ«ã‚¦ãƒ©ãƒ©", "ãƒãƒ³ãƒ–ãƒ¼ãƒ¡ãƒ¢ãƒªãƒ¼", "ãƒ“ã‚³ãƒ¼ãƒšã‚¬ã‚µã‚¹",
    "ãƒ’ã‚·ã‚¢ã‚±ãƒœãƒ", "ãƒ’ã‚·ã‚¢ãƒã‚¾ãƒ³", "ãƒ’ã‚·ãƒŸãƒ©ã‚¯ãƒ«", "ãƒ“ãƒªãƒ¼ãƒ´", "ãƒ“ãƒ¯ãƒãƒ¤ãƒ’ãƒ‡", "ãƒ•ã‚¡ã‚¤ãƒ³ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³", "ãƒ–ã‚¨ãƒŠãƒ“ã‚¹ã‚¿", "ãƒ•ã‚§ãƒãƒ¼ãƒ¡ãƒ",
    "ãƒ•ã‚µã‚¤ãƒãƒ‘ãƒ³ãƒ‰ãƒ©", "ãƒ•ã‚¸ã‚­ã‚»ã‚­", "ãƒ–ãƒ©ã‚¹ãƒˆãƒ¯ãƒ³ãƒ”ãƒ¼ã‚¹", "ãƒ•ãƒªã‚ªãƒ¼ã‚½", "ãƒ›ãƒƒã‚³ãƒ¼ã‚¿ãƒ«ãƒã‚¨", "ãƒãƒ¼ãƒ™ãƒ©ã‚¹ã‚µãƒ³ãƒ‡ãƒ¼", "ãƒãƒã‚«ãƒã‚¿ãƒ³ãƒ›ã‚¤ã‚¶",
    "ãƒãƒã‚«ãƒãƒ•ã‚¯ã‚­ã‚¿ãƒ«", "ãƒãƒ¤ãƒãƒˆãƒƒãƒ—ã‚¬ãƒ³", "ãƒãƒ«ã‚¼ãƒ³ã‚¹ã‚­ãƒ¼", "ãƒãƒ³ãƒãƒƒã‚¿ãƒ³ã‚«ãƒ•ã‚§", "ãƒŸã‚¹ã‚¿ãƒ¼ã‚·ãƒ¼ãƒ“ãƒ¼", "ãƒŸãƒ›ãƒãƒ–ãƒ«ãƒœãƒ³",
    "ãƒ¡ã‚¤ã‚·ãƒ§ã‚¦ãƒ‰ãƒˆã‚¦", "ãƒ¡ã‚¸ãƒ­ã‚¢ãƒ«ãƒ€ãƒ³", "ãƒ¡ã‚¸ãƒ­ãƒ‰ãƒ¼ãƒ™ãƒ«", "ãƒ¡ã‚¸ãƒ­ãƒ‘ãƒ¼ãƒãƒ¼", "ãƒ¡ã‚¸ãƒ­ãƒ–ãƒ©ã‚¤ãƒˆ", "ãƒ¡ã‚¸ãƒ­ãƒãƒƒã‚¯ã‚¤ãƒ¼ãƒ³", "ãƒ¡ã‚¸ãƒ­ãƒ©ã‚¤ã‚¢ãƒ³",
    "ãƒ¡ã‚¸ãƒ­ãƒ©ãƒ¢ãƒ¼ãƒŒ", "ãƒ¤ã‚¨ãƒãƒ ãƒ†ã‚­", "ãƒ¤ãƒãƒ‹ãƒ³ã‚¼ãƒ•ã‚¡ãƒ¼", "ãƒ¦ã‚­ãƒãƒ“ã‚¸ãƒ³", "ãƒ©ã‚¤ã‚¹ã‚·ãƒ£ãƒ¯ãƒ¼", "ãƒ©ã‚¤ãƒ³ã‚¯ãƒ©ãƒ•ãƒˆ", "ãƒ©ãƒ´ã‚ºã‚ªãƒ³ãƒªãƒ¼ãƒ¦ãƒ¼",
    "ãƒ©ãƒƒã‚­ãƒ¼ãƒ©ã‚¤ãƒ©ãƒƒã‚¯", "ãƒ­ã‚¤ã‚¹ã‚¢ãƒ³ãƒ‰ãƒ­ã‚¤ã‚¹", "ãƒ¯ãƒ³ãƒ€ãƒ¼ã‚¢ã‚­ãƒ¥ãƒ¼ãƒˆ"
}
normalized_umamusume = {unicodedata.normalize("NFKC", n).strip().lower() for n in umamusume_bloodlines}

# === è¡€çµ±ãƒã‚¸ã‚·ãƒ§ãƒ³ ===
def generate_position_labels():
    def dfs(pos, depth, max_depth):
        if depth > max_depth: return []
        result = [pos]
        result += dfs(pos + "çˆ¶", depth + 1, max_depth)
        result += dfs(pos + "æ¯", depth + 1, max_depth)
        return result
    return dfs("", 0, 5)[1:]
POSITION_LABELS = generate_position_labels()

# === é¦¬ãƒªãƒ³ã‚¯å–å¾—ï¼ˆrequestsç‰ˆï¼‰ ===
def get_horse_links(race_id):
    url = f"https://race.netkeiba.com/race/shutuba.html?race_id={race_id}"
    res = requests.get(url, headers=HEADERS)
    res.encoding = "EUC-JP"
    soup = BeautifulSoup(res.text, "html.parser")

    horse_links = {}
    tables = soup.find_all("table", class_="RaceTable01")
    for table in tables:
        for a in table.find_all("a", href=True):
            if "/horse/" in a["href"]:
                name = a.get_text(strip=True)
                full_url = "https://db.netkeiba.com" + a["href"]
                if len(name) >= 2 and name not in horse_links:
                    horse_links[name] = full_url
    return horse_links

# === è¡€çµ±å–å¾—ï¼†ç…§åˆ ===
def get_pedigree_with_positions(horse_url):
    horse_id = horse_url.rstrip("/").split("/")[-1]
    ped_url = f"https://db.netkeiba.com/horse/ped/{horse_id}/"
    res = requests.get(ped_url, headers=HEADERS)
    res.encoding = "EUC-JP"
    soup = BeautifulSoup(res.text, "html.parser")
    table = soup.find("table", class_="blood_table")
    if not table:
        return {}
    names = {}
    td_list = table.find_all("td")
    for i, td in enumerate(td_list[:len(POSITION_LABELS)]):
        label = POSITION_LABELS[i]
        a = td.find("a")
        if a and a.text.strip():
            names[label] = a.text.strip()
    return names

def match_umamusume(pedigree_dict):
    return [f"ã€{pos}ã€‘{name}" for pos, name in pedigree_dict.items()
            if unicodedata.normalize("NFKC", name).strip().lower() in normalized_umamusume]

def analyze_race(race_id):
    horse_links = get_horse_links(race_id)
    st.text(f"ğŸ å‡ºèµ°é¦¬æ•°: {len(horse_links)}é ­")

    result = []
    for name, link in horse_links.items():
        try:
            pedigree = get_pedigree_with_positions(link)
            matches = match_umamusume(pedigree)
            result.append({
                "é¦¬å": name,
                "è©²å½“è¡€çµ±æ•°": len(matches),
                "ã‚¦ãƒå¨˜è¡€çµ±": "\n".join(matches)
            })
            time.sleep(1.0)
        except Exception as e:
            result.append({
                "é¦¬å": name,
                "è©²å½“è¡€çµ±æ•°": "å–å¾—å¤±æ•—",
                "ã‚¦ãƒå¨˜è¡€çµ±": str(e)
            })
    return result

# === UI ===
st.title("ã‚¦ãƒå¨˜è¡€çµ±ã®é¦¬ğŸ‡ã‚µãƒ¼ãƒ<br>ï¼ˆæœ€æ–°1ã‹æœˆé–“å¯¾å¿œï¼‰")

schedule_df = pd.read_csv("jra_2025_keibabook_schedule.csv")

# âœ… æ—¥ä»˜æ•´å½¢ã®ä¿®æ­£ãƒã‚¤ãƒ³ãƒˆï¼ˆã“ã“ï¼‰
schedule_df["æ—¥ä»˜"] = pd.to_datetime(
    schedule_df["å¹´"].astype(str) + "/" + schedule_df["æœˆæ—¥(æ›œæ—¥)"].str.extract(r"(\d{2}/\d{2})")[0],
    format="%Y/%m/%d"
)

today = pd.Timestamp.today()
past_31 = today - pd.Timedelta(days=31)
schedule_df = schedule_df[schedule_df["æ—¥ä»˜"].between(past_31, today)]

# ğŸ“… æ—¥ä»˜é¸æŠï¼ˆæœ€æ–°ãŒä¸Šï¼‰
dates = sorted(schedule_df["æ—¥ä»˜"].dt.strftime("%Y-%m-%d").unique(), reverse=True)
selected_date = st.selectbox("ç«¶é¦¬é–‹å‚¬æ—¥ã‚’é¸æŠã—ã¦ãã ã•ã„ï¼ˆéå»31æ—¥ã¾ã§é¡ã‚Œã¾ã™ã€‚ï¼‰", dates)
data_filtered = schedule_df[schedule_df["æ—¥ä»˜"].dt.strftime("%Y-%m-%d") == selected_date]

# ğŸ‡ ç«¶é¦¬å ´é¸æŠï¼ˆãƒœã‚¿ãƒ³å½¢å¼ï¼‰
st.markdown("### ğŸŸï¸ ç«¶é¦¬å ´ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
place_codes = {"æœ­å¹Œ": "01", "å‡½é¤¨": "02", "ç¦å³¶": "03", "æ–°æ½Ÿ": "04", "æ±äº¬": "05",
               "ä¸­å±±": "06", "ä¸­äº¬": "07", "äº¬éƒ½": "08", "é˜ªç¥": "09", "å°å€‰": "10"}
available_places = sorted(data_filtered["ç«¶é¦¬å ´"].unique())
cols = st.columns(5)
if "place" not in st.session_state:
    st.session_state.place = None
for i, p in enumerate(available_places):
    if cols[i % 5].button(p):
        st.session_state.place = p
place = st.session_state.place
if not place:
    st.stop()

# ğŸ ãƒ¬ãƒ¼ã‚¹ç•ªå·ãƒœã‚¿ãƒ³
st.markdown("### ğŸ ãƒ¬ãƒ¼ã‚¹ç•ªå·ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
cols = st.columns(6)
if "race_num_int" not in st.session_state:
    st.session_state.race_num_int = None
for i in range(12):
    if cols[i % 6].button(f"{i+1}R"):
        st.session_state.race_num_int = i + 1
race_num_int = st.session_state.race_num_int
if not race_num_int:
    st.stop()

selected_row = data_filtered[data_filtered["ç«¶é¦¬å ´"] == place].iloc[0]
jj = place_codes[place]
kk = f"{int(selected_row['é–‹å‚¬å›']):02d}"
dd = f"{int(selected_row['æ—¥ç›®']):02d}"
race_id = f"{selected_row['å¹´']}{jj}{kk}{dd}{race_num_int:02d}"
st.markdown(f"ğŸ”¢ **race_id**: `{race_id}`")

# å®Ÿè¡Œãƒœã‚¿ãƒ³
if st.button("ğŸ‡ ã‚¦ãƒå¨˜è¡€çµ±ã®ãŠé¦¬ã•ã‚“ã‚µãƒ¼ãƒã‚’é–‹å§‹ã—ã¾ã™"):
    with st.spinner("ç…§åˆä¸­..."):
        results = analyze_race(race_id)
        st.success("ç…§åˆå®Œäº†ï¼")

        if not results:
            st.warning("å‡ºèµ°é¦¬ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        else:
            st.markdown("### ğŸ§¬ ã‚¦ãƒå¨˜è¡€çµ±ã‚µãƒ¼ãƒçµæœ")
            for idx, row in enumerate(results):
                st.markdown(f"""
<div style='font-size:20px; font-weight:bold;'>{idx+1}. {row['é¦¬å']}</div>

è©²å½“è¡€çµ±æ•°ï¼š{row['è©²å½“è¡€çµ±æ•°']}  
{row['ã‚¦ãƒå¨˜è¡€çµ±']}
""", unsafe_allow_html=True)
                if idx < len(results) - 1:
                    st.markdown("<hr style='border:1px solid #ccc;'>", unsafe_allow_html=True)
